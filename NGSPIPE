#!/usr/bin/env python


if __name__ == '__main__':
    import os
    import glob
    import json
    import shutil
    import sqlite3
    import argparse
    import subprocess

    from ngsscriptlibrary import samplesheet_to_sample_genesis
    from ngsscriptlibrary import parse_samplesheet_for_pipeline
    from ngsscriptlibrary import get_captures
    from ngsscriptlibrary import TargetDatabase
    from ngsscriptlibrary import run_command
    from ngsscriptlibrary import create_dir
    from ngsscriptlibrary import create_empty_excelfile
    from ngsscriptlibrary import read_config_json
    from ngsscriptlibrary import move_data_to_diagnostic_tree

    parser = argparse.ArgumentParser()
    parser.add_argument("-s", "--serie", type=str, 
                        help="Miseq serie nummer", required=True)
    parser.add_argument("--samplesheet", type=str,
                        help="Sample sheet (afwijkend van BaseSpace)")
    parser.add_argument("-t", "--threads", type=int, default=10,
                        help="Number of threads for snakemake")
    parser.add_argument("-p", "--pipeline", action='store_true',
                        help="Only run the pipeline")
    parser.add_argument("--download", action='store_true',
                        help="Download reads from basespace")
    parser.add_argument("--cleanup", action='store_true',
                        help="Move data to archive")
    parser.add_argument("--hester", action='store_true',
                        help="Run is rehybed @ MiSeq")
    parser.add_argument("--demultiplex", nargs='?', default=False, const='2', 
                        type=str, help="Run is re-analyzed @ BaseSpace")
    parser.add_argument("--niek", action='store_true',
                        help="Remove serie from databases")
    parser.add_argument("--unlock", action='store_true',
                        help="Unlock snakemake")
    parser.add_argument("--notemp", action='store_true',
                        help="Do not remove temporary files")                                                 

    args = parser.parse_args()

    serie = args.serie
    threads = args.threads
    basespace_serie = serie
    project = args.demultiplex

    assert not serie.startswith('CTD'), "Verkeerde pipeline. Gebruik de CTD pipeline voor CTD series."

    if args.hester:
        basespace_serie = r'{}\ \(2\)'.format(serie)

    if not args.download and not args.pipeline and not args.cleanup:
        args.download = True
        args.pipeline = True
        args.cleanup = True

    BASEDIR = '/data/dnadiag/reads'
    ARCHIEF = '/mnt/kg_nextgen_archief/IlluminaRawData/'
    SCRIPTHOME = '/data/dnadiag/ngspipeline/'
    CONFIG = os.path.join(SCRIPTHOME, 'ngspipeline', 'config.yaml')
    CONFIG_JSON = os.path.join(SCRIPTHOME, 'ngspipeline', 'config.json')
    READS = os.path.join(BASEDIR, 'MS{}'.format(serie))
    BASEMOUNT = os.path.join(BASEDIR, 'basespace')
    SERIEDIR = os.path.join('/', 'mnt', 'ngs', 'Analyse*MiSEQ', 'MiSeq*Serie*{}*'.format(serie))
    SNPCHECKDIR = os.path.join(SERIEDIR, 'SNPcheck')
    STANDARDFRAGS = os.path.join(SERIEDIR, 'Miseq*{}*std*fragmenten2.xlsx'.format(serie))
    
    config_dict = read_config_json(CONFIG_JSON)
    TARGETDB = os.path.join(config_dict["TARGET"], 'varia', 'captures.sqlite') 


    #Test SERIEDIR for B series:
    test_dirs = glob.glob(SERIEDIR)
    if len(test_dirs) > 1:
        for test_dir in test_dirs:
            test = test_dir.split('/')[-1]
            if '_' in test:
                test = test.split('_')[0]
            if test.endswith(str(serie)):
                SERIEDIR = test_dir.replace(' ', '*')
    
    if args.samplesheet:
        SAMPLESHEET = args.samplesheet
    else:
        SAMPLESHEET = os.path.join(BASEMOUNT, 'Runs', basespace_serie, 'Files', 'SampleSheet.csv')

    if args.niek:
        databases = glob.glob('{}/*.sqlite'.format(config_dict['DB']))
        for database in databases:
            DeleteSerie(database, serie).delete_serie_from_tables()
        
        parsed_samplesheet = parse_samplesheet_for_pipeline(SAMPLESHEET, TARGETDB)
        captures = get_captures(parsed_samplesheet)
        for capture in captures:
            run_command('CNV -c {} -s {} --delete'.format(capture, serie))

    for _ in glob.iglob('{}/*'.format(SERIEDIR)):
        if _.endswith('Data-analyse'):
            OUTPUTDIR = _

    if args.download:
        
        os.mkdir(READS)

        try:
            glob.glob(STANDARDFRAGS)[0]
        except IndexError:
            pass
        else:
            run_command('cp {} {}/standaardfragmenten.xlsx'.format(STANDARDFRAGS, READS))

        run_command('cp -r {} {}'.format(SNPCHECKDIR, READS))

        run_command('basemount {} -c ormook'.format(BASEMOUNT))

        if project:
            run_command(r'cp -r {}/basespace/Projects/{}/Samples/*\({}\)/Files/*.gz {}'.format(BASEDIR, serie, project, READS))
        else:
            run_command('cp -r {}/basespace/Projects/{}/Samples/*/Files/*.gz {}'.format(BASEDIR, serie, READS))
        run_command('cp {} {}/SampleSheet.csv'.format(SAMPLESHEET, READS))


        try:
            os.mkdir('{}/MiSeqRunMetrics/{}'.format(ARCHIEF, serie))
        except FileExistsError as e:
            pass
        else:
            run_command('cp {}/Runs/{}/Files/*.txt {}/MiSeqRunMetrics/{}'.format(BASEMOUNT, basespace_serie, ARCHIEF, serie))
            run_command('cp {}/Runs/{}/Files/*.xml {}/MiSeqRunMetrics/{}'.format(BASEMOUNT, basespace_serie, ARCHIEF, serie))
            run_command('cp -r {}/Runs/{}/Files/InterOp {}/MiSeqRunMetrics/{}'.format(BASEMOUNT, basespace_serie, ARCHIEF, serie))
            run_command('cp {} {}/MiSeqRunMetrics/{}'.format(SAMPLESHEET, ARCHIEF, serie))

        run_command('basemount --unmount {}'.format(BASEMOUNT))

    if args.pipeline:
        samples = [_[0] for _ in samplesheet_to_sample_genesis('{}/SampleSheet.csv'.format(READS)) if not 'amplicon' in _[0].lower()]
        
        for sample in samples:
            snpcheckfile = os.path.join(READS, 'SNPcheck', '{}.qpcrsnpcheck'.format(sample))
            if not os.path.isfile(snpcheckfile):
                run_command('touch {}'.format(snpcheckfile))
        
        run_snakemake = 'snakemake --rerun-incomplete -s {}/ngspipeline/captures.snakefile -j{} --configfile {} --directory {}'.format(SCRIPTHOME, threads, CONFIG, READS)
        run_snakemake_amplicons = 'snakemake --rerun-incomplete -s {}/ngspipeline/amplicons.snakefile -j{} --configfile {} --directory {}'.format(SCRIPTHOME, threads, CONFIG, READS)
        
        if args.unlock:
            run_snakemake = f'{run_snakemake} --unlock'
            run_snakemake = f'{run_snakemake_amplicons} --unlock'
        if args.notemp:
            run_snakemake = f'{run_snakemake} --notemp'
            run_snakemake = f'{run_snakemake_amplicons} --notemp'

        run_command(run_snakemake)
        run_command(run_snakemake_amplicons)

    if args.cleanup:
        amplicon_genesiscodes = TargetDatabase(TARGETDB).get_amplicon_genesiscode()
        samples = samplesheet_to_sample_genesis('{}/SampleSheet.csv'.format(READS))
        move_data_to_diagnostic_tree(samples, OUTPUTDIR, READS, serie, amplicon_genesiscodes)
        try:
            os.mkdir('{}/MiSeq/Diagnostiek/MS{}'.format(ARCHIEF, serie))
        except FileExistsError as e:
            pass
        else:
            run_command('cp {}/reads/*.gz {}/MiSeq/Diagnostiek/MS{}'.format(READS, ARCHIEF, serie))
        finally:
            run_command('cp {}/output/*.xlsx {}/output/*.pdf {}/output/input.json {}/MiSeq/Diagnostiek/MS{}'.format(READS, READS, READS, ARCHIEF, serie))
        run_command("rsync -rlzuvP /data/dnadiag/databases/ /mnt/kg_nextgen_archief/ServerDatabaseArchief/")
